#!/usr/bin/env python3
"""
Document Quality Validator - Ensure generated documents meet standards

This script validates markdown documents (especially generated ones) for:
- Completeness: No TODO markers or missing sections
- Structure: Proper markdown hierarchy and formatting
- Content Quality: Sufficient detail and explanations
- Actionability: Clear, specific instructions
- Security Coverage: Appropriate security considerations

Designed to work with documents generated by generate_phase_plan_v2.py
but can validate any markdown document against quality standards.

Usage:
    python3 scripts/validate_workplan.py path/to/document.md
    python3 scripts/validate_workplan.py --config config.json --check-generation
    python3 scripts/validate_workplan.py document.md --quiet

The validator is algorithmic (no AI/LLM) and checks documents against
rules that ensure professional quality output.
"""

import sys
import json
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum


class ValidationLevel(Enum):
    """Severity levels for validation issues."""
    ERROR = "ERROR"
    WARNING = "WARNING"
    INFO = "INFO"


@dataclass
class ValidationIssue:
    """Represents a validation issue found in the work plan."""
    level: ValidationLevel
    category: str
    message: str
    line_number: Optional[int] = None
    context: Optional[str] = None


class WorkPlanValidator:
    """
    Validates document quality using rule-based checks.
    
    This validator implements multiple quality checks:
    - Completeness: Ensures no placeholders or missing content
    - Structure: Validates markdown formatting and hierarchy
    - Quality: Checks for sufficient detail and explanations
    - Actionability: Ensures instructions are clear and specific
    - Security: Verifies security considerations are addressed
    
    The validator can be subclassed for document-specific validation.
    Override check methods to add custom validation rules.
    
    Architecture:
        - validate_file(): Main entry point
        - _check_*(): Individual validation checks
        - print_report(): Formats results for display
    """
    
    def __init__(self):
        """
        Initialize validator with empty state.
        
        Issues are collected during validation and categorized by severity:
        - ERROR: Must fix before document is usable
        - WARNING: Should fix for quality
        - INFO: Suggestions for improvement
        """
        self.issues: List[ValidationIssue] = []
        self.lines: List[str] = []
        self.content: str = ""
        
    def validate_file(self, file_path: str) -> Tuple[bool, List[ValidationIssue]]:
        """Validate a work plan file."""
        path = Path(file_path)
        
        if not path.exists():
            self.issues.append(ValidationIssue(
                ValidationLevel.ERROR,
                "File",
                f"Work plan file not found: {file_path}"
            ))
            return False, self.issues
        
        with open(path, 'r', encoding='utf-8') as f:
            self.content = f.read()
            self.lines = self.content.splitlines()
        
        # Run all validation checks
        self._check_completeness()
        self._check_structure()
        self._check_markdown_quality()
        self._check_content_quality()
        self._check_actionability()
        self._check_security_coverage()
        
        # Determine if validation passed
        has_errors = any(issue.level == ValidationLevel.ERROR for issue in self.issues)
        return not has_errors, self.issues
    
    def _check_completeness(self):
        """
        Check for TODO markers and missing content.
        
        TODO markers indicate incomplete content that needs to be filled.
        This is a critical check - documents with TODOs are not ready for use.
        
        Also validates that required sections exist in the document.
        Required sections can be customized by overriding this method.
        """
        # Check for TODO markers - these indicate incomplete content
        todo_pattern = re.compile(r'\[TODO[:\s].*?\]', re.IGNORECASE)
        for i, line in enumerate(self.lines, 1):
            if todo_match := todo_pattern.search(line):
                self.issues.append(ValidationIssue(
                    ValidationLevel.ERROR,
                    "Completeness",
                    f"TODO marker found: {todo_match.group()}",
                    line_number=i,
                    context=line.strip()
                ))
        
        # Check required sections exist
        required_sections = [
            "## Prerequisites",
            "## Quick Reference",
            "## Overview",
            "## Development Methodology",
            "## Done Criteria",
            "## Work Breakdown"
        ]
        
        for section in required_sections:
            if section not in self.content:
                self.issues.append(ValidationIssue(
                    ValidationLevel.ERROR,
                    "Completeness",
                    f"Missing required section: {section}"
                ))
    
    def _check_structure(self):
        """Check document structure and organization."""
        # Check header hierarchy
        header_pattern = re.compile(r'^(#{1,6})\s+(.+)$')
        header_levels = []
        
        for i, line in enumerate(self.lines, 1):
            if match := header_pattern.match(line):
                level = len(match.group(1))
                title = match.group(2)
                header_levels.append((level, title, i))
        
        # Verify header hierarchy is consistent
        for i in range(1, len(header_levels)):
            current_level = header_levels[i][0]
            prev_level = header_levels[i-1][0]
            
            if current_level > prev_level + 1:
                self.issues.append(ValidationIssue(
                    ValidationLevel.WARNING,
                    "Structure",
                    f"Header level jumped from {prev_level} to {current_level}",
                    line_number=header_levels[i][2],
                    context=f"# {'#' * (current_level-1)} {header_levels[i][1]}"
                ))
        
        # Check for phase header
        if not header_levels or not header_levels[0][1].startswith("Phase"):
            self.issues.append(ValidationIssue(
                ValidationLevel.ERROR,
                "Structure",
                "Document must start with 'Phase X: Title - Work Plan' header"
            ))
    
    def _check_markdown_quality(self):
        """Check markdown formatting and syntax."""
        # Check for broken links
        link_pattern = re.compile(r'\[([^\]]+)\]\(([^)]+)\)')
        for i, line in enumerate(self.lines, 1):
            for match in link_pattern.finditer(line):
                link_text = match.group(1)
                link_url = match.group(2)
                
                # Check for empty links
                if not link_url or link_url.isspace():
                    self.issues.append(ValidationIssue(
                        ValidationLevel.ERROR,
                        "Markdown",
                        f"Empty link URL for '{link_text}'",
                        line_number=i
                    ))
        
        # Check code blocks are properly closed
        in_code_block = False
        code_block_start = 0
        
        for i, line in enumerate(self.lines, 1):
            if line.strip().startswith("```"):
                if not in_code_block:
                    in_code_block = True
                    code_block_start = i
                else:
                    in_code_block = False
        
        if in_code_block:
            self.issues.append(ValidationIssue(
                ValidationLevel.ERROR,
                "Markdown",
                "Unclosed code block",
                line_number=code_block_start
            ))
        
        # Check for consistent list formatting
        list_pattern = re.compile(r'^(\s*)[-*+]\s+(.+)$')
        bullet_chars = set()
        
        for i, line in enumerate(self.lines, 1):
            if match := list_pattern.match(line):
                bullet_chars.add(line.strip()[0])
        
        if len(bullet_chars) > 1:
            self.issues.append(ValidationIssue(
                ValidationLevel.WARNING,
                "Markdown",
                f"Inconsistent bullet characters used: {bullet_chars}"
            ))
    
    def _check_content_quality(self):
        """
        Check content quality and narrative flow.
        
        Quality checks include:
        - Sections have sufficient content (not just headers)
        - Tasks include contextual tips or guidance
        - Content demonstrates narrative flow, not just bullet points
        
        These checks help ensure generated documents are as good as
        hand-written ones.
        """
        # Track content per section to ensure substance
        section_pattern = re.compile(r'^##\s+(.+)$')
        current_section = None
        section_content = {}
        
        for line in self.lines:
            if match := section_pattern.match(line):
                current_section = match.group(1)
                section_content[current_section] = []
            elif current_section and line.strip():
                section_content[current_section].append(line)
        
        # Verify sections have substantial content
        min_lines = {
            "Prerequisites": 5,
            "Overview": 3,
            "Development Methodology": 5,
            "Work Breakdown": 20
        }
        
        for section, min_count in min_lines.items():
            if section in section_content:
                line_count = len(section_content[section])
                if line_count < min_count:
                    self.issues.append(ValidationIssue(
                        ValidationLevel.WARNING,
                        "Content Quality",
                        f"Section '{section}' seems too brief ({line_count} lines, "
                        f"expected at least {min_count})"
                    ))
        
        # Check for contextual explanations in tasks
        task_pattern = re.compile(r'^####\s+Task\s+\d+\.\d+\.\d+:')
        task_count = 0
        tasks_with_context = 0
        
        in_task = False
        has_context = False
        
        for line in self.lines:
            if task_pattern.match(line):
                if in_task and not has_context:
                    self.issues.append(ValidationIssue(
                        ValidationLevel.WARNING,
                        "Content Quality",
                        "Task lacks contextual explanation or tips"
                    ))
                task_count += 1
                in_task = True
                has_context = False
            elif in_task and any(marker in line for marker in ['💡', '⚠️', '🔒', '⚡']):
                has_context = True
                tasks_with_context += 1
        
        # Check last task
        if in_task and has_context:
            tasks_with_context += 1
        
        if task_count > 0 and tasks_with_context / task_count < 0.5:
            self.issues.append(ValidationIssue(
                ValidationLevel.WARNING,
                "Content Quality",
                f"Only {tasks_with_context}/{task_count} tasks have contextual tips"
            ))
    
    def _check_actionability(self):
        """
        Check that content provides clear, actionable guidance.
        
        Actionable content includes:
        - Specific commands that can be executed
        - Clear file paths and locations
        - Concrete examples, not abstract descriptions
        
        This ensures readers can actually follow the instructions.
        """
        # Check for vague instructions that provide no real guidance
        vague_phrases = [
            "do something",
            "implement stuff",
            "add code",
            "make changes",
            "update files",
            "fix issues"
        ]
        
        for i, line in enumerate(self.lines, 1):
            lower_line = line.lower()
            for phrase in vague_phrases:
                if phrase in lower_line:
                    self.issues.append(ValidationIssue(
                        ValidationLevel.WARNING,
                        "Actionability",
                        f"Vague instruction found: '{phrase}'",
                        line_number=i,
                        context=line.strip()
                    ))
        
        # Check for specific file paths and commands
        command_pattern = re.compile(r'`([^`]+)`')
        commands_found = []
        
        for match in command_pattern.finditer(self.content):
            command = match.group(1)
            if any(cmd in command for cmd in ['just', 'cargo', 'scripts/', '.sh']):
                commands_found.append(command)
        
        if len(commands_found) < 5:
            self.issues.append(ValidationIssue(
                ValidationLevel.WARNING,
                "Actionability",
                f"Few executable commands found ({len(commands_found)}), "
                "work plan may lack specific instructions"
            ))
        
        # Check for code examples
        code_blocks = re.findall(r'```\w+\n[\s\S]*?```', self.content)
        if len(code_blocks) < 3:
            self.issues.append(ValidationIssue(
                ValidationLevel.WARNING,
                "Actionability",
                f"Only {len(code_blocks)} code examples found, "
                "consider adding more for clarity"
            ))
    
    def _check_security_coverage(self):
        """Check that security considerations are addressed."""
        security_keywords = [
            "security",
            "sensitive",
            "sanitiz",
            "redact",
            "PII",
            "password",
            "token",
            "authentic"
        ]
        
        security_mentions = 0
        for keyword in security_keywords:
            security_mentions += len(re.findall(keyword, self.content, re.IGNORECASE))
        
        if security_mentions < 5:
            self.issues.append(ValidationIssue(
                ValidationLevel.WARNING,
                "Security",
                f"Limited security coverage ({security_mentions} mentions), "
                "ensure security is adequately addressed"
            ))
        
        # Check for security section or requirements
        has_security_section = ("## Security" in self.content or 
                               "### Security" in self.content or
                               security_mentions >= 3)
        
        if not has_security_section:
            self.issues.append(ValidationIssue(
                ValidationLevel.ERROR,
                "Security",
                "No security section or requirements found"
            ))
    
    def validate_config(self, config_path: str) -> Tuple[bool, List[ValidationIssue]]:
        """Validate a configuration file for completeness."""
        path = Path(config_path)
        
        if not path.exists():
            self.issues.append(ValidationIssue(
                ValidationLevel.ERROR,
                "Config",
                f"Configuration file not found: {config_path}"
            ))
            return False, self.issues
        
        try:
            with open(path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except json.JSONDecodeError as e:
            self.issues.append(ValidationIssue(
                ValidationLevel.ERROR,
                "Config",
                f"Invalid JSON: {e}"
            ))
            return False, self.issues
        
        # Load schema
        schema_path = Path(__file__).parent.parent / ".claude" / "schemas" / "workplan-content-schema.json"
        if schema_path.exists():
            with open(schema_path, 'r') as f:
                schema = json.load(f)
            
            # Basic validation against required fields
            self._validate_against_schema(config, schema)
        
        has_errors = any(issue.level == ValidationLevel.ERROR for issue in self.issues)
        return not has_errors, self.issues
    
    def _validate_against_schema(self, config: Dict, schema: Dict, path: str = ""):
        """Recursively validate config against schema."""
        if "required" in schema:
            for field in schema["required"]:
                if field not in config:
                    self.issues.append(ValidationIssue(
                        ValidationLevel.ERROR,
                        "Config Schema",
                        f"Missing required field: {path}.{field}" if path else field
                    ))
        
        if "properties" in schema:
            for field, field_schema in schema["properties"].items():
                if field in config:
                    new_path = f"{path}.{field}" if path else field
                    if field_schema.get("type") == "object":
                        self._validate_against_schema(config[field], field_schema, new_path)
                    elif field_schema.get("type") == "array" and field_schema.get("items"):
                        for i, item in enumerate(config[field]):
                            if field_schema["items"].get("type") == "object":
                                self._validate_against_schema(
                                    item, 
                                    field_schema["items"], 
                                    f"{new_path}[{i}]"
                                )
    
    def print_report(self, issues: List[ValidationIssue]):
        """Print a formatted validation report."""
        if not issues:
            print("✅ Validation PASSED - No issues found!")
            return
        
        # Group by level
        errors = [i for i in issues if i.level == ValidationLevel.ERROR]
        warnings = [i for i in issues if i.level == ValidationLevel.WARNING]
        info = [i for i in issues if i.level == ValidationLevel.INFO]
        
        print("=" * 70)
        print("WORK PLAN VALIDATION REPORT")
        print("=" * 70)
        
        if errors:
            print(f"\n❌ ERRORS ({len(errors)}):")
            for issue in errors:
                self._print_issue(issue)
        
        if warnings:
            print(f"\n⚠️  WARNINGS ({len(warnings)}):")
            for issue in warnings:
                self._print_issue(issue)
        
        if info:
            print(f"\nℹ️  INFO ({len(info)}):")
            for issue in info:
                self._print_issue(issue)
        
        print("\n" + "=" * 70)
        print(f"Summary: {len(errors)} errors, {len(warnings)} warnings, {len(info)} info")
        
        if errors:
            print("\n❌ Validation FAILED - Please fix errors before using this work plan")
        else:
            print("\n✅ Validation PASSED - Work plan meets quality standards")
    
    def _print_issue(self, issue: ValidationIssue):
        """Print a single issue with formatting."""
        location = f"Line {issue.line_number}: " if issue.line_number else ""
        print(f"\n  [{issue.category}] {location}{issue.message}")
        if issue.context:
            print(f"    Context: {issue.context}")


def main():
    """CLI entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Validate work plan quality and completeness"
    )
    parser.add_argument(
        "file",
        nargs="?",
        help="Path to WORK_PLAN.md file to validate"
    )
    parser.add_argument(
        "--config",
        help="Validate a configuration file instead"
    )
    parser.add_argument(
        "--check-generation",
        action="store_true",
        help="Generate work plan from config and validate result"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Only show summary, not detailed issues"
    )
    
    args = parser.parse_args()
    
    if not args.file and not args.config:
        parser.error("Either file or --config must be specified")
    
    validator = WorkPlanValidator()
    
    if args.config:
        if args.check_generation:
            # Generate and validate
            import subprocess
            import tempfile
            
            # First validate config
            passed, issues = validator.validate_config(args.config)
            if not passed and not args.quiet:
                validator.print_report(issues)
                sys.exit(1)
            
            # Generate work plan
            script_dir = Path(__file__).parent
            generator_script = script_dir / "generate_phase_plan_v2.py"
            
            with tempfile.TemporaryDirectory() as tmpdir:
                result = subprocess.run(
                    [sys.executable, str(generator_script), args.config, tmpdir],
                    capture_output=True,
                    text=True
                )
                
                if result.returncode != 0:
                    print(f"Generation failed: {result.stderr}")
                    sys.exit(1)
                
                # Find generated file
                output_match = re.search(r'Generated narrative work plan: (.+)', result.stdout)
                if output_match:
                    generated_file = output_match.group(1)
                    # Validate generated file
                    validator.issues = []  # Reset issues
                    passed, issues = validator.validate_file(generated_file)
        else:
            # Just validate config
            passed, issues = validator.validate_config(args.config)
    else:
        # Validate work plan file
        passed, issues = validator.validate_file(args.file)
    
    if not args.quiet:
        validator.print_report(issues)
    
    sys.exit(0 if passed else 1)


if __name__ == "__main__":
    main()